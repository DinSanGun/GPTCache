mode: mock

paths:
  out_dir: results/suite/mock_exact
  artifacts_dir: results/suite/mock_exact/artifacts
  reset_artifacts: true

cache:
  type: exact
  eviction: FIFO         # bench_policies.py will override per run
  max_size: 64           # you’ll sweep this via CLI
  clean_size: 1
  # similarity fields are ignored in exact mode (kept for consistency)
  similarity: distance
  similarity_threshold: 1.0
  cost_metric: latency_ms
  cost_decay: 0.0

run:
  prompts_file: "data/lmsys_user_prompts_expbiased_60k.txt"
  strict_cold: true
  shuffle_warm: true
  warm_repeats: 1

  # bench-only synthetic latency (requires the small helper in runner.py).
  # If you don’t have that helper, set the env vars listed under the commands.
  mock_latency:
    profile: bimodal
    hi_ms: 20
    lo_ms: 1
    hi_frac: 0.30
    jitter_ms: 2
