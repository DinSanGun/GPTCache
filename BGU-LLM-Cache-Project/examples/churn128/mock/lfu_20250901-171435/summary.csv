mode,cache,paths,run,overrides,sys_cpu_pct_mean,sys_cpu_pct_max,sys_rss_mb_peak,wall_s,throughput_rps,mean_ms,p95_ms,p99_ms,hit_rate,hit_rate_cold,hit_rate_warm,cost_saved_total
mock,"{'type': 'semantic', 'eviction': 'LFU', 'max_size': 64, 'clean_size': 8, 'similarity': 'distance', 'similarity_threshold': 0.98, 'cost_metric': 'latency_ms', 'cost_decay': 0.0}","{'out_dir': 'C:/dev/LLM-Caching/GPTCache/BGU-LLM-Cache-Project/results/suite/mock_semantic/churn128/mock/lfu_20250901-171435', 'artifacts_dir': 'C:/dev/LLM-Caching/GPTCache/BGU-LLM-Cache-Project/results/suite/mock_semantic/churn128/mock/lfu_20250901-171435/artifacts', 'reset_artifacts': True}","{'prompts_file': 'C:/dev/LLM-Caching/GPTCache/BGU-LLM-Cache-Project/data/lmsys_user_prompts_heavy.txt', 'strict_cold': True, 'shuffle_warm': True, 'warm_repeats': 1, 'mock_latency': {'profile': 'bimodal', 'hi_ms': 8, 'lo_ms': 1, 'hi_frac': 0.3, 'jitter_ms': 2}, 'prompts': 120}","{'knobs_file': True, 'env': {'CACHE_MAX_SIZE': 8, 'CACHE_SIMILARITY_THRESHOLD': 0.1}, 'cli': {'eviction': 'LFU', 'max_size': 64, 'clean_size': 8, 'similarity': None, 'sim_thr': 0.98, 'cost_metric': None, 'cost_decay': None, 'prompts': 120, 'warm_repeats': 1, 'shuffle_warm': False, 'no_shuffle_warm': False, 'strict_cold': False, 'no_strict_cold': False, 'out_dir': None}}",58.6281179138322,85.9,353.16796875,132.6067235469818,1.8098629811554718,552.4356383330693,850.9650001069531,905.5839000502601,0.1,0.0,0.2,9490.804
